{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183e88d7",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a1a138",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/brendanmiles/nyt-news-dataset-20082021\n",
    "\n",
    "We perform text preprocessing of the news data. We are interested in the titles and abstracts of the news. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a94a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968a308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa00c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NYT_Dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a521f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['title','abstract']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f08d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation+'»«“”’'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5866ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(data):\n",
    "    data = data.str.lower() # change to lower capital\n",
    "    data =  data.str.replace('’s',' ')\n",
    "    data = data.str.replace(r'[\\d|\\n]',' ') # remove digits\n",
    "    data = data.apply(lambda x: contractions.fix(x)) # convert contractions into full form\n",
    "    data = data.str.replace('[{}]'.format(punctuation), ' ') # remove punctuation\n",
    "    data = data.fillna('') # fill 'nan' with ''\n",
    "    data = data.apply(lambda x: x.split()) \n",
    "    data = data.apply(lambda x: [wnl.lemmatize(y) for y in x]) # Lemmatization\n",
    "    data = data.apply(lambda x: ' '.join(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2686e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract'] = clean_doc(df['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b864d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = clean_doc(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fdf11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(data):\n",
    "    length = []\n",
    "    for i,txt in enumerate(data.tolist()):\n",
    "        length.append(len(txt.split()))\n",
    "    return length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5a42e1",
   "metadata": {},
   "source": [
    "We add \"ssstarttt\" at the start and \"eeenddd\" at the end of each title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fca66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(lambda x: 'ssstarttt ' + x + ' eeenddd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f13469f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_abstract = word_count(df['abstract'])\n",
    "length_title = word_count(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a478f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47.0, 17.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(length_abstract,99), np.percentile(length_title,99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5adb0d7",
   "metadata": {},
   "source": [
    "Most of abstracts have about 50 words and most of titles have 20 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d3a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq(data, min_freq=5):\n",
    "    textlist = []\n",
    "    for i in data.str.split():\n",
    "        textlist += i\n",
    "\n",
    "    count = Counter(textlist)\n",
    "    count =  dict(count)\n",
    "\n",
    "    count_rare = 0\n",
    "    for key, value in count.items():\n",
    "        if value < min_freq:\n",
    "            count_rare += 1\n",
    "    return count_rare, len(count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "567abc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([df['abstract'], df['title']], axis=0)\n",
    "num_rare, tot_num = count_freq(temp,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76725719",
   "metadata": {},
   "source": [
    "num_rare = number of rare words (below 3 occurrence in the dataset)\n",
    "<br>\n",
    "tot_num = total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39f0c491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25483, 50370, 24887)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rare, tot_num, tot_num-num_rare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc14cd8",
   "metadata": {},
   "source": [
    "There are 25000 words which are common words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e403dec",
   "metadata": {},
   "source": [
    "Split data into train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "059def50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split=0.1):\n",
    "    size = data.shape[0]\n",
    "    split = int(size*(1-split))\n",
    "    return data.iloc[:split], data.iloc[split:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab55fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = split_data(df, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "865f5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(train, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "536ab0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "val = val.dropna()\n",
    "test = test.dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
